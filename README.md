# Finetuning Bert for Sentiment Analysis
Finetuning Bert for Sentiment Analysis for reviews in simplified Chinese

This project focused on sentiment analysis of product reviews in simplified Chinese, categorizing the output into negative, positive, and neutral sentiments. bert-base-chinese in the Bert tokenizer was used for word embedding. Subsequently, bert-base-chinese in BertForSequenceClassification was employed to train our model. The model achieved an accuracy score of 0.8823 on the test data.

### Reference
https://github.com/SaifAlmaliki/Bert-NLP
