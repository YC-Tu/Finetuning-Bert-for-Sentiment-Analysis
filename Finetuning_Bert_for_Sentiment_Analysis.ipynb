{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0ab617xfcwD"
      },
      "source": [
        "# **Finetuning Bert for Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZA7Ni1r2fL76"
      },
      "source": [
        "### **Using tensorflow & GPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wayHTXMp_EL",
        "outputId": "df83e6e8-aa93-4bb3-be2f-ccd3b0072d32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM6VJ_evsD0j",
        "outputId": "51f61dbc-bf1e-4bf1-dbb2-11d127680086",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejpeL8o95C_j",
        "outputId": "5699879e-c742-4101-e019-9ad6358afd5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.35)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.40 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.40)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvVnRqYy5SL9",
        "outputId": "f0300b4b-9632-4aa4-8017-2f6fea08e195",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "print(\"tensorflow version : \", tf.__version__)\n",
        "print(\"tensorflow_hub version : \", hub.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow version :  1.15.0\n",
            "tensorflow_hub version :  0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fE1WfQ--vjo"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THes5XpNfvOf"
      },
      "source": [
        "### Training Data\n",
        "\n",
        "https://drive.google.com/open?id=15wh7uahh6RNQcFI_9w3M3LZt5dn1PQQI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFs9zeSJQWsl",
        "outputId": "80acc54f-1acd-4b46-f85c-f00c2395e711",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "import pandas as pd\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "file_id = '15wh7uahh6RNQcFI_9w3M3LZt5dn1PQQI'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('all_training_data.csv')\n",
        "data0 = pd.read_csv('all_training_data.csv')\n",
        "print(data0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Unnamed: 0                  0  1\n",
            "0              0           千呼万唤始出来，  0\n",
            "1              1   尼康的APSC小相机终于发布了，  0\n",
            "2              2  COOLPIX A. 你怎么看呢？  0\n",
            "3              3     我看，尼康是挤牙膏挤惯了啊，  0\n",
            "4              4       1，外观既没有V1时尚，  1\n",
            "...          ...                ... ..\n",
            "5773        5773            下面附点样片，  0\n",
            "5774        5774              随便拍的，  0\n",
            "5775        5775   大部分都是JPG、鲜艳模式直出，  0\n",
            "5776        5776            技术确实不精，  0\n",
            "5777        5777             望大家海涵。  0\n",
            "\n",
            "[5778 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQW5WgwRRsg5",
        "outputId": "4d4f3ba6-d889-41c5-8af1-ca10a2a5ff40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data = data0\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>千呼万唤始出来，</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>尼康的APSC小相机终于发布了，</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>COOLPIX A. 你怎么看呢？</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>我看，尼康是挤牙膏挤惯了啊，</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1，外观既没有V1时尚，</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                  0  1\n",
              "0           0           千呼万唤始出来，  0\n",
              "1           1   尼康的APSC小相机终于发布了，  0\n",
              "2           2  COOLPIX A. 你怎么看呢？  0\n",
              "3           3     我看，尼康是挤牙膏挤惯了啊，  0\n",
              "4           4       1，外观既没有V1时尚，  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPAxoYaI6qaT"
      },
      "source": [
        "sentences = data['0']\n",
        "labels = data['1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhAvyBc_SHKi",
        "outputId": "5a1164a8-8b72-43ca-dbcc-f28a14d863d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5778"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Data\n",
        "https://drive.google.com/file/d/1Z407wytknTvwQhbiyfzL6ZkXL5o5DmeO/view?usp=sharing"
      ],
      "metadata": {
        "id": "ClVt0XW2S1px"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8mKZnZhisxW",
        "outputId": "b4468d59-e970-4768-aa58-d8a706211e33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "import pandas as pd\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "file_id = '1Z407wytknTvwQhbiyfzL6ZkXL5o5DmeO'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('testHAHA.csv')\n",
        "dataTe = pd.read_csv('testHAHA.csv')\n",
        "print(dataTe)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Unnamed: 0                                        0   2\n",
            "0              0  一直潜水，昨天入d300s +35 1.8g，谈谈感受，dx说，标题一定要长！   0\n",
            "1              1                              在我们这尼康一个代理商   0\n",
            "2              2                             开的大型体验中心提的货，   0\n",
            "3              3                             老板和销售mm都很热情，   0\n",
            "4              4                                     不欺诈，   0\n",
            "...          ...                                      ...  ..\n",
            "1390        1390                                 并且位置非常好，  49\n",
            "1391        1391                         这可能是地球上最难奈的相机机身。  49\n",
            "1392        1392             如果您想要一台可以拍出几乎所有东西而又不是奥林巴斯的相机  49\n",
            "1393        1393                 （即使在三脚架上也能给您带来很多很多机会错失），  49\n",
            "1394        1394                              那么这台相机很适合您。  49\n",
            "\n",
            "[1395 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YUUgEEpf1xv"
      },
      "source": [
        "### **Import BERT for word embedding (using bert-base-chinese)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PC2uBt_7Ely",
        "outputId": "a84c7aee-7dbd-4042-b8e8-fd6fdc3185b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUbjKzRpgDID"
      },
      "source": [
        "### **word embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH18ePbq8PCm",
        "outputId": "02ffc907-9c8b-4bbd-d715-2ed90b224495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "input_ids = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  千呼万唤始出来，\n",
            "Token IDs: [101, 1283, 1461, 674, 1542, 1993, 1139, 3341, 8024, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "c03d435b-1376-4ae3-f474-849dcd64a321",
        "id": "ifavs4fb8TjD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "a1a98b8a-6365-4b57-8fa7-b569c57996b3",
        "id": "Q1Y0G3cB8TjH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# maximum sequence length\n",
        "MAX_LEN = 128\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\",\n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 128 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud5E61628Z4r"
      },
      "source": [
        "# attention masks\n",
        "attention_masks = []\n",
        "\n",
        "for sent in input_ids:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoxQJqFV8wzP"
      },
      "source": [
        "# split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels,\n",
        "                                                            random_state=8467, test_size=0.1)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=8467, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki4RqcGh80qd"
      },
      "source": [
        "# Convert inputs and labels into torch tensors\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.from_numpy(np.array(train_labels))\n",
        "validation_labels = torch.from_numpy(np.array(validation_labels))\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdbuUDkP-8Y7"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "# DataLoader for training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# DataLoader for validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsbYkI13gMDT"
      },
      "source": [
        "### **Setting up Model：bert-base-chinese，num_labels set to3**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7MTm-tS_Etp",
        "outputId": "af5c5b61-cea1-48b0-8f30-d4e72e506e55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-chinese\",\n",
        "    num_labels = 3, # 3 categories\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "# run on GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a_pVtDn_Lke",
        "outputId": "588b58bb-d90a-4fc7-90c8-79bcdceafdc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "# the model's parameters.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (21128, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (3, 768)\n",
            "classifier.bias                                                 (3,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xxp8ZtEgXDD"
      },
      "source": [
        "### **Setting up Optimizer：lr = 2e-5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbmN-VLQ_dAm"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgxzOLjF_jXf"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl8WLqnVALOV"
      },
      "source": [
        "import numpy as np\n",
        "# accuracy\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOOb5U1MAM9v"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    #returns hh:mm:ss\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uKODT8pggCf"
      },
      "source": [
        "### **Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsp8i-jjAOxt",
        "outputId": "79fe7b55-4257-42c9-ea93-6d3852f76f60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "import random\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "loss_values = []\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    ###Training###\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # `batch` contains\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        outputs = model(b_input_ids,\n",
        "                    token_type_ids=None,\n",
        "                    attention_mask=b_input_mask,\n",
        "                    labels=b_labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # training loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "    ### Validation ###\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, logit predictions.\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask)\n",
        "        logits = outputs[0]\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    325.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    325.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    325.    Elapsed: 0:00:29.\n",
            "  Batch   160  of    325.    Elapsed: 0:00:38.\n",
            "  Batch   200  of    325.    Elapsed: 0:00:48.\n",
            "  Batch   240  of    325.    Elapsed: 0:00:57.\n",
            "  Batch   280  of    325.    Elapsed: 0:01:07.\n",
            "  Batch   320  of    325.    Elapsed: 0:01:16.\n",
            "\n",
            "  Average training loss: 0.45\n",
            "  Training epcoh took: 0:01:17\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    325.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    325.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    325.    Elapsed: 0:00:29.\n",
            "  Batch   160  of    325.    Elapsed: 0:00:38.\n",
            "  Batch   200  of    325.    Elapsed: 0:00:48.\n",
            "  Batch   240  of    325.    Elapsed: 0:00:57.\n",
            "  Batch   280  of    325.    Elapsed: 0:01:07.\n",
            "  Batch   320  of    325.    Elapsed: 0:01:16.\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Training epcoh took: 0:01:17\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    325.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    325.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    325.    Elapsed: 0:00:29.\n",
            "  Batch   160  of    325.    Elapsed: 0:00:38.\n",
            "  Batch   200  of    325.    Elapsed: 0:00:48.\n",
            "  Batch   240  of    325.    Elapsed: 0:00:57.\n",
            "  Batch   280  of    325.    Elapsed: 0:01:07.\n",
            "  Batch   320  of    325.    Elapsed: 0:01:16.\n",
            "\n",
            "  Average training loss: 0.16\n",
            "  Training epcoh took: 0:01:17\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.90\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7m5PjQ6gnZH"
      },
      "source": [
        "### **Loss Plot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lsj3JZtAj_5",
        "outputId": "68cfe496-0135-4182-b3b7-4a75d3ee9d7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "sns.set(font_scale=1.5)\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "plt.plot(loss_values, 'b-o')\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZEFYQJPRERERGRBmMATEREREVmQ/w8KcvYvbn9PUwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-byCX4JgwCE"
      },
      "source": [
        "### **Test Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaSKcec-G33i",
        "outputId": "ee107957-e82c-4ff5-c1f7-3f1174792b69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "dataTe.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>一直潜水，昨天入d300s +35 1.8g，谈谈感受，dx说，标题一定要长！</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>在我们这尼康一个代理商</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>开的大型体验中心提的货，</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>老板和销售mm都很热情，</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>不欺诈，</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                        0  2\n",
              "0           0  一直潜水，昨天入d300s +35 1.8g，谈谈感受，dx说，标题一定要长！  0\n",
              "1           1                              在我们这尼康一个代理商  0\n",
              "2           2                             开的大型体验中心提的货，  0\n",
              "3           3                             老板和销售mm都很热情，  0\n",
              "4           4                                     不欺诈，  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHEGOe_6sXvY",
        "outputId": "ba58d6a5-acda-4132-b74c-27102f0d8c92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(dataTe)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1395"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVZbBACZGHEt"
      },
      "source": [
        "import pandas as pd\n",
        "sentences = dataTe['0']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6WsUE0_mTzt",
        "outputId": "8db7a443-5713-4dfd-fe82-7ca5ae99d49d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentences[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'一直潜水，昨天入d300s +35 1.8g，谈谈感受，dx说，标题一定要长！'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRbZYmyIIXeS"
      },
      "source": [
        "# Tokenize sentences\n",
        "input_ids = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN,\n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "attention_masks = []\n",
        "\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)\n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC-nBBj8g0y2"
      },
      "source": [
        "### **Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7sJCSTfI61M",
        "outputId": "c89c6403-3f3e-4992-ac48-77f5c2cf4a16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask = batch\n",
        "\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None,\n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 1,395 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9TB5SIHhFEN"
      },
      "source": [
        "### **Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4UNLz5qJXP2",
        "outputId": "a41f256d-2a41-4bd3-ebba-2d9c50f138bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "for i in range(len(true_labels)):\n",
        "\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "\n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:872: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt2hONdRJkyT",
        "outputId": "4a1c9644-1a6f-4b3d-e578-616f6e488d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.631\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAVMaQdWJpW6",
        "outputId": "1667c9bd-1767-4e5f-ec52-959f599f700b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
        "accuracy = accuracy_score(flat_true_labels, flat_predictions)\n",
        "precision = precision_score(flat_true_labels, flat_predictions, average='macro')\n",
        "recall = recall_score(flat_true_labels, flat_predictions, average='macro')\n",
        "fscore = f1_score(flat_true_labels, flat_predictions, average='macro')\n",
        "\n",
        "print(\"Accuracy: %g\\tPrecision: %g\\tRecall: %g\\tF-score: %g\" % (\n",
        "    accuracy, precision, recall, fscore))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.882353\tPrecision: 0.722687\tRecall: 0.732148\tF-score: 0.727334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phITIvR9hbkJ"
      },
      "source": [
        "### **Results on the Test Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEEhv6NtKWzH",
        "outputId": "7625a69e-c9a2-418e-fa19-19593d74ef1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "flat_predictions[0:99]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQoAJG2gKc-E",
        "outputId": "f39e0098-2300-4e4b-ae59-beaa7a6d7feb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "np.array(flat_true_labels[0:99])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 2, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "       2, 0, 0, 0, 0, 2, 0, 0, 2, 1, 1, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0,\n",
              "       2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9ugo2Kgm4Gi"
      },
      "source": [
        "dataNew = dataTe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj9ktflQnOxP"
      },
      "source": [
        "dataNew['pred'] = flat_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff8wOGnlnXPD",
        "outputId": "e79e358e-fcbb-4688-d7e2-4b6d1822a459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "dataNew.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>2</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>一直潜水，昨天入d300s +35 1.8g，谈谈感受，dx说，标题一定要长！</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>在我们这尼康一个代理商</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>开的大型体验中心提的货，</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>老板和销售mm都很热情，</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>不欺诈，</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                        0  2  pred\n",
              "0           0  一直潜水，昨天入d300s +35 1.8g，谈谈感受，dx说，标题一定要长！  0     0\n",
              "1           1                              在我们这尼康一个代理商  0     0\n",
              "2           2                             开的大型体验中心提的货，  0     0\n",
              "3           3                             老板和销售mm都很热情，  0     0\n",
              "4           4                                     不欺诈，  0     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqmZhHxahlqa"
      },
      "source": [
        "### **Format Conversion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvltNKV0nZJK"
      },
      "source": [
        "New_pred = []\n",
        "for i in flat_predictions:\n",
        "    if i == 0:\n",
        "        New_pred.append(\"neutral\")\n",
        "    elif i == 1:\n",
        "        New_pred.append(\"negative\")\n",
        "    else:\n",
        "        New_pred.append(\"positive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kg69x5WoVUu",
        "outputId": "5a43d3b2-0f1e-4bf9-c0e6-7e217912d00d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        }
      },
      "source": [
        "dataNew.tail(26)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>2</th>\n",
              "      <th>pred</th>\n",
              "      <th>New_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1369</th>\n",
              "      <td>1369</td>\n",
              "      <td>虽然论坛最近吵得很厉害，</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1370</th>\n",
              "      <td>1370</td>\n",
              "      <td>但不可否认宾得是个相对低调的厂商。</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1371</th>\n",
              "      <td>1371</td>\n",
              "      <td>我真的很喜欢这款相机的感觉和操作，</td>\n",
              "      <td>49</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1372</th>\n",
              "      <td>1372</td>\n",
              "      <td>但是软件和图像质量却完全不同。</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1373</th>\n",
              "      <td>1373</td>\n",
              "      <td>我的第一个K-1持续了几个月才停止保存图像-如果我拍摄了五十张照片，</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1374</th>\n",
              "      <td>1374</td>\n",
              "      <td>它可能会保存前三个图像。</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1375</th>\n",
              "      <td>1375</td>\n",
              "      <td>在对相机和存储卡进行了广泛的测试和重新格式化以及使用不同的存储卡后，</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1376</th>\n",
              "      <td>1376</td>\n",
              "      <td>问题仍然存在，</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1377</th>\n",
              "      <td>1377</td>\n",
              "      <td>然后我将K-1换成了功能齐全的替代品。</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1378</th>\n",
              "      <td>1378</td>\n",
              "      <td>有时会出现其他软件“故障”，</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1379</th>\n",
              "      <td>1379</td>\n",
              "      <td>但没有可重复性。</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1380</th>\n",
              "      <td>1380</td>\n",
              "      <td>我购买此相机是因为我想要全画幅画质，</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1381</th>\n",
              "      <td>1381</td>\n",
              "      <td>而无需支付佳能/尼康溢价。</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1382</th>\n",
              "      <td>1382</td>\n",
              "      <td>相反，我使用的两个机身的图​​像质量都与我的Olympus OM-D EM-1相当或略逊一筹</td>\n",
              "      <td>49</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1383</th>\n",
              "      <td>1383</td>\n",
              "      <td>这款相机不仅比旧相机老了三年，</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1384</th>\n",
              "      <td>1384</td>\n",
              "      <td>而且比全画幅微镜4/3的传感器。</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1385</th>\n",
              "      <td>1385</td>\n",
              "      <td>这种图像质量非常令人失望，</td>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1386</th>\n",
              "      <td>1386</td>\n",
              "      <td>但是宾得K-1机身也会遭受最差的自动对焦和对焦</td>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1387</th>\n",
              "      <td>1387</td>\n",
              "      <td>（如果我曾经使用过任何ILC镜头）。</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1388</th>\n",
              "      <td>1388</td>\n",
              "      <td>从好的方面来说，</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1389</th>\n",
              "      <td>1389</td>\n",
              "      <td>这台相机的操作手感觉很棒，</td>\n",
              "      <td>49</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1390</th>\n",
              "      <td>1390</td>\n",
              "      <td>并且位置非常好，</td>\n",
              "      <td>49</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1391</th>\n",
              "      <td>1391</td>\n",
              "      <td>这可能是地球上最难奈的相机机身。</td>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1392</th>\n",
              "      <td>1392</td>\n",
              "      <td>如果您想要一台可以拍出几乎所有东西而又不是奥林巴斯的相机</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1393</th>\n",
              "      <td>1393</td>\n",
              "      <td>（即使在三脚架上也能给您带来很多很多机会错失），</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1394</th>\n",
              "      <td>1394</td>\n",
              "      <td>那么这台相机很适合您。</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ...  New_pred\n",
              "1369        1369  ...   neutral\n",
              "1370        1370  ...   neutral\n",
              "1371        1371  ...  positive\n",
              "1372        1372  ...   neutral\n",
              "1373        1373  ...   neutral\n",
              "1374        1374  ...   neutral\n",
              "1375        1375  ...   neutral\n",
              "1376        1376  ...   neutral\n",
              "1377        1377  ...   neutral\n",
              "1378        1378  ...   neutral\n",
              "1379        1379  ...   neutral\n",
              "1380        1380  ...   neutral\n",
              "1381        1381  ...   neutral\n",
              "1382        1382  ...  positive\n",
              "1383        1383  ...   neutral\n",
              "1384        1384  ...   neutral\n",
              "1385        1385  ...  negative\n",
              "1386        1386  ...  negative\n",
              "1387        1387  ...   neutral\n",
              "1388        1388  ...   neutral\n",
              "1389        1389  ...  positive\n",
              "1390        1390  ...  positive\n",
              "1391        1391  ...  negative\n",
              "1392        1392  ...   neutral\n",
              "1393        1393  ...   neutral\n",
              "1394        1394  ...   neutral\n",
              "\n",
              "[26 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooyjkhT2oZGG"
      },
      "source": [
        "dataNew['New_pred'] = New_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AksBhTxuo8c8",
        "outputId": "c3683b6b-f0e3-4d1c-c4e9-723b9b316861",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sent = list(dataNew['2'] )\n",
        "sent[1:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihCOazTgoiYp"
      },
      "source": [
        "tmpQ = -1\n",
        "whole = []\n",
        "tmpC = 0\n",
        "tmp = \"\"\n",
        "for every in sent:\n",
        "    if every == tmpQ:\n",
        "        tmp += New_pred[tmpC]\n",
        "        tmp += \"    \"\n",
        "        tmpC += 1\n",
        "    else:\n",
        "        tmpQ = every\n",
        "        whole.append(tmp)\n",
        "        tmp = \"\"\n",
        "        tmp += New_pred[tmpC]\n",
        "        tmp += \"    \"\n",
        "        tmpC += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sQhHy0epNQk",
        "outputId": "f2772a6c-4cf7-4fdc-d99a-a120e6568f3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "whole[0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " 'neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    negative    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    positive    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    positive    negative    positive    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    negative    neutral    neutral    neutral    neutral    positive    neutral    neutral    neutral    neutral    neutral    neutral    neutral    negative    neutral    negative    neutral    negative    negative    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    ',\n",
              " 'neutral    neutral    positive    neutral    neutral    ',\n",
              " 'neutral    neutral    neutral    negative    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    negative    positive    neutral    neutral    neutral    negative    positive    neutral    neutral    neutral    neutral    positive    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    positive    ',\n",
              " 'neutral    positive    neutral    neutral    neutral    ',\n",
              " 'neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    positive    neutral    negative    positive    neutral    neutral    ',\n",
              " 'neutral    neutral    neutral    positive    negative    neutral    neutral    neutral    ',\n",
              " 'neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    positive    neutral    neutral    neutral    positive    neutral    positive    negative    neutral    negative    neutral    neutral    neutral    negative    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    negative    neutral    neutral    neutral    neutral    neutral    negative    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    ',\n",
              " 'neutral    neutral    neutral    ',\n",
              " 'neutral    neutral    neutral    neutral    neutral    neutral    positive    neutral    positive    positive    neutral    positive    neutral    neutral    neutral    neutral    neutral    neutral    negative    neutral    neutral    neutral    positive    positive    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    negative    neutral    neutral    positive    neutral    positive    neutral    neutral    neutral    neutral    neutral    ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KSldtd2psGo",
        "outputId": "a6bdad22-3c64-428d-d66b-48e1a5c4426c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "new_whole = whole[1:]\n",
        "new_whole[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    negative    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    positive    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    positive    negative    positive    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    negative    neutral    neutral    neutral    neutral    negative    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    ',\n",
              " 'neutral    neutral    neutral    neutral    neutral    ',\n",
              " 'neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    positive    positive    neutral    neutral    neutral    negative    neutral    neutral    neutral    neutral    neutral    positive    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    positive    ',\n",
              " 'neutral    positive    neutral    neutral    neutral    ',\n",
              " 'neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    positive    neutral    neutral    neutral    neutral    negative    neutral    negative    neutral    negative    positive    neutral    neutral    ',\n",
              " 'neutral    neutral    neutral    positive    negative    neutral    neutral    neutral    ',\n",
              " 'neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    positive    neutral    neutral    neutral    positive    neutral    positive    negative    neutral    negative    neutral    neutral    neutral    negative    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    negative    neutral    neutral    neutral    neutral    neutral    negative    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    ',\n",
              " 'neutral    neutral    positive    ',\n",
              " 'neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    positive    positive    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    negative    neutral    neutral    neutral    positive    positive    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    neutral    negative    neutral    positive    neutral    negative    neutral    neutral    neutral    neutral    neutral    ',\n",
              " 'neutral    neutral    neutral    neutral    ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyPd0LLzqHIJ"
      },
      "source": [
        "tmpQ = -1\n",
        "whole = []\n",
        "tmpC = 0\n",
        "tmp = []\n",
        "for every in sent:\n",
        "    if every == tmpQ:\n",
        "        tmp.append(New_pred[tmpC])\n",
        "        tmpC += 1\n",
        "    else:\n",
        "        tmpQ = every\n",
        "        whole.append(tmp)\n",
        "        tmp = []\n",
        "        tmp.append(New_pred[tmpC])\n",
        "        tmpC += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPpFc_cTrnFa",
        "outputId": "adeb22c0-063e-4389-9081-32bc2e455bf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "new_whole = whole[1:]\n",
        "new_whole[:1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'negative',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'positive',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'positive',\n",
              "  'negative',\n",
              "  'positive',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'negative',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'negative',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral',\n",
              "  'neutral']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHMZVZBthw1u"
      },
      "source": [
        "### **Export Data（Final Results）**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To2fRaijt2z3"
      },
      "source": [
        "import csv\n",
        "with open('output22.tsv', 'w', newline='') as f_output:\n",
        "    tsv_output = csv.writer(f_output, delimiter='\\t')\n",
        "    for i in range(len(new_whole)):\n",
        "      tsv_output.writerow(new_whole[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_5P-TCvtRPQ"
      },
      "source": [
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCk7XGN2tmj7"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('output22.tsv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}